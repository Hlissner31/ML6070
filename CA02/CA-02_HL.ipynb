{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "055d50a5-56a8-4e9a-9436-1ac7c7b919d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Import all other necessary libraries. Your code below ...\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4baabb4c-8388-4c5c-bf55-7db9abb732f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for creating list of words\n",
    "def make_Dictionary(file_loc):\n",
    "  word_total = []    #empty list to contain all words from emails\n",
    "  emails = [os.path.join(file_loc,f) for f in os.listdir(file_loc)]    #use list comprehension to retrieve all emails in directory\n",
    "    #Open each email and run through loop\n",
    "  for email in emails:\n",
    "    with open(email) as e:      #use with to ensure each email is opened and then closed\n",
    "      for line in e:\n",
    "        words = line.split()          #split words on at white space\n",
    "        word_total += words          #add new words to word total\n",
    "  dictionary = Counter(word_total)          #use Counter to count how many times each word appears\n",
    "  list_to_remove = list(dictionary)     #Cleaning list of words\n",
    "\n",
    "  for item in list_to_remove:\n",
    "    if item.isalpha() == False:       #remove nonalphabet words\n",
    "      del dictionary[item]\n",
    "    elif len(item) == 1:         #remove any characters with a length of 1\n",
    "      del dictionary[item]\n",
    "  dictionary = dictionary.most_common(3000)         #only keep the 3000 most common words\n",
    "    #return dictionary\n",
    "  return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bf8df2a-b971-45fa-864e-f2c44a162d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for extracting words from emails and assigning them to spam or not\n",
    "def extract_features(email_dir):\n",
    "  files = [os.path.join(email_dir,ed) for ed in os.listdir(email_dir)]     #create path to email files\n",
    "  features_matrix = np.zeros((len(files),3000)) #create feature matrix with a length of 3000 given our dictionary is limited to the top 3000 words\n",
    "  train_labels = np.zeros(len(files)) #train labels allows us to assign a 0 or a 1 or each email indicating if the email is spam or not\n",
    "  count = 1;    #count of spam emails?\n",
    "  docID = 0;     #docID used to keep track of what document the loop is on in the list\n",
    "    #loop over all files\n",
    "  for file in files:\n",
    "    with open(file) as fi:\n",
    "        #go through each line of the file\n",
    "      for i, line in enumerate(fi):\n",
    "        if i ==2:          #stop at line 3\n",
    "          words = line.split()             #split words on whitespace on line 3\n",
    "            #look at each word collected\n",
    "          for word in words:               #reset word_score to 0 for each new loop\n",
    "            word_score = 0               #try to map each word to a word in the dictionary\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word: #if match of word is found in dictionary then set that words score to the corrosponding in the dictionary\n",
    "                word_score = i\n",
    "                features_matrix[docID,word_score] = words.count(word)\n",
    "      train_labels[docID] = 0; #set default state for each email as not spam\n",
    "      filepathTokens = file.split('/') #extract part of path\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1] #extract last part of file name\n",
    "      if lastToken.startswith(\"spmsg\"): #check if file name starts with \"spmsg\" if so set email to spam\n",
    "        train_labels[docID] = 1; #updates document with completed file\n",
    "        count = count + 1 #both increment the counts of the loop\n",
    "      docID = docID + 1\n",
    "  return features_matrix, train_labels     #return the completed features_matrix and train_labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e4b76f3-eb6c-404f-b83c-fa312e593715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "TRAIN_DIR = 'Data/train-mails'\n",
    "TEST_DIR = 'Data/test-mails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b26b608-3ee9-46e2-a131-6775c7b26905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "dictionary = make_Dictionary(TRAIN_DIR) #calls make_Dictionary function of TRAIN_DIR : collects 3000 most common words and their frequency\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "#calls extract_features on both train and test data sets\n",
    "features_matrix, labels = extract_features(TRAIN_DIR) \n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
    "#return is each email as vector of word counts (features_matrix) and label of spam or not spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2f9679a-fc3e-4749-b779-fa6c16f390db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emails(directory): #load emails and place them into empty lists with the emails and labels for the emails\n",
    "    emails, labels = [], []\n",
    "    for filename in os.listdir(directory): #retrieve file names\n",
    "        filepath = os.path.join(directory, filename) #get full path to files\n",
    "        with open(filepath, \"r\", encoding=\"latin1\") as file:\n",
    "            content = file.read() \n",
    "            emails.append(content) #email is read and appended to the the content list\n",
    "            labels.append(1 if filename.startswith(\"spmsg\") else 0)  # 1 for spam, 0 for ham\n",
    "    return emails, np.array(labels) # return emails and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cac7b0a1-2df8-4fd6-9ea2-b905f5fbe453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "train_emails, train_labels = load_emails(TRAIN_DIR)\n",
    "test_emails, test_labels = load_emails(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c14d52b9-fd23-4762-a16c-9e821e51c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into numerical features using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=3000) #max features at 3000 for our limit\n",
    "# Apply the vectorizer to the training emails and store the features\n",
    "train_features = vectorizer.fit_transform(train_emails).toarray()\n",
    "# Apply the vectorizer to the training emails and store the features\n",
    "test_features = vectorizer.transform(test_emails).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b841e92-9c27-408a-b452-b1f2f18a2b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naive Bayes algorithm...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes model\n",
    "print(\"Training Model using Gaussian Naive Bayes algorithm...\")\n",
    "model = GaussianNB() #better for normally distributed data\n",
    "model.fit(train_features, train_labels) #fit with test and train labels\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89a96b91-c272-497c-a195-5ec1f83ecacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing trained model to predict Test Data labels...\n",
      "Completed classification of the Test Data.\n",
      "Now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "0.9461538461538461\n"
     ]
    }
   ],
   "source": [
    "#Predict labels for test data\n",
    "print(\"Testing trained model to predict Test Data labels...\")\n",
    "predicted_labels = model.predict(test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(\"Completed classification of the Test Data.\")\n",
    "print(\"Now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6c50cb4-3ce1-46d6-a550-2b4f35c2a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Multinomial Naive Bayes algorithm...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes model\n",
    "print(\"Training Model using Multinomial Naive Bayes algorithm...\")\n",
    "model = MultinomialNB() #models multinomial distribution better\n",
    "model.fit(train_features, train_labels) #fit with test and train labels\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e97d6dc7-9fba-492d-a47a-aa8dff7a6c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing trained model to predict Test Data labels...\n",
      "Completed classification of the Test Data.\n",
      "Now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "0.9846153846153847\n"
     ]
    }
   ],
   "source": [
    "#Predict labels for test data\n",
    "print(\"Testing trained model to predict Test Data labels...\")\n",
    "predicted_labels = model.predict(test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(\"Completed classification of the Test Data.\")\n",
    "print(\"Now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
